### 🚀 아파치 카프카 개요 및 설명
카프카가 무엇인지? 
카프카를 통해 할 수 있는 일? 
왜 카프카를 사용하는 지? 

`Before Kafka` 
(단방향 동기 통신) 
- 소스 어플리케이션과 타켓 어플리케이션이 개수가 늘어날 수록 데이터 전송 라인이 많아져 배포, 장애 대응하기 어려움.
- 그로 인해 데이터 통신 프로토콜 파편화 심해짐
- 추후 데이터의 포맷이 변경되면 엉켜있는 라인에 모두 수정되어야 하기 때문에 유지보수 어려워짐.

`After kafka`
- 아파치 카프카는 이런 복잡성을 해결하기 위해 링크드인에서 내부적으로 개발해서 오픈 소스로 제공 중
- 소스 어플리케이션과 타켓 어플리케이션의 느슨함을 위해 나왔습니다.

`정리`
- 카프카는 유연한 큐 역할을 한다.
- 고가용성으로 렉이 내려가도 데이터를 손실 없이 복구할 수 있다.
- 낮은 지연과 높은 처리량으로 빅데이터 처리를 한다.


### 🚀 토픽이란?
- 데이터를 담는 데이터베이스와 파일 시스템과 유사하다.
- 토픽은 이름을 지정할 수 잇다. 목적에 따라 무슨 데이터를 담는 지 명확하게 지정하면 된다.
- 토픽안에 파티션으로 구성되어 있다.

`동일 데이터에 대해서 두번 처리할 수 있는 방법은?`
- 컨슈머 그룹이 다른 경우 
- auto.offset.reset = earliest
  
es에 저장해서 시각화 하기도 한다.
파티션 늘릴 수 있지만 줄일 수 없음.

`파티션의 레코드는 언제 삭제 되는 가?`
- log.retention.ms : 최대 record 보존시간
- log.retention.byte : 최대 record 보존 크기


### 🚀 브로커, 복제, ISR(In-Sync-Replication)

`복제`
- 클러스트에서 서버가 장애가 발생할 때, 카프카의 가용성을 보장하는 가장 좋은 방법이 *복제*이기 때문입니다.

`Kafka Broker`
- 카프카가 설치되어 있는 서버 단위를 말합니다.
- 보통 3개 이상의 브로커로 구성하여 사용하는 것을 권장합니다.

`partition&replication`
- 파티션의 복제를 뜻합니다.
- case1) partition : 1 replication : 1 
파티션 1개, 복제 0개

- case2) partition : 1 replication : 3 

파티션 1개, 복제 2개

 
- 브로커의 개수에 따라서 replication 개수가 제한된다.
- 예를 들어 브로커 개수 3개면 replication 최대 3개까지 설정가능. 즉, 4개 될 수 없다는 뜻
- 그러므로, *브로커의 개수 맞게 파티션과 레플리케이션이 설정*되어야 한다.

 

Leader 파티션 (원본), Follower 파티션 (복제)
- 2개의 파티션을 합쳐서 `ISR` 이라고 부른다.

 
`왜 replication 사용하는 것 일까요?`
- 파티션의 고가용성을 위해 사용됩니다.
- Leader 파티션이 문제가 발생했을 때 Flower 파티션이 승계해서 처리할 수 있도록 한다.

`프로듀서 옵션 : ack`
- ack 를 통해 고가용성을 유지할 수 있습니다.
- 이 옵션이 파티션의 레플리케이션과 관련이 있습니다.

`Replication&ack 옵션`
- 0 : 리더 파티션에 전송하고 응답값 받지 않음.
  - 정상적으로 전송됬는지, 복제 파티션에 복제가 되었는 지 알 수 없음. 보장할 수 없다. 속도는 빠르지만 데이터 유실 가능성이 있다.
- 1 : 리더 파티션에 전송하고 응답값을 받습니다.
  - 정상적으로 전송됬는지, 다만 나머지 복제 파티션에 복제가 되었는 지 알 수 없다.
- all : 리더 파티션에 전송하고 응답값을 받습니다.
  - 정상적으로 전송됬는지, 복제 파티션에 복제가 되었는지 응답 받을 수 있다.
  - 데이터 유실 없음. 속도가 현저히 느리다.
 

-> 따라서 카프카에 들어오는 데이터량과 retention date 저장시간을 잘 생각하셔서 replication개수를 정하는 게 좋다.

```
ack의 옵션과 처리속도에 대해서
결국 두마리 토끼(속도/유실)를 잡을 수 없다는 것을 명심하셔서 옵션을 정하시면 좋을것 같아요.
ack를 all로 할 경우에는 replication이 다 된것을 확인하기 때문에 말씀대로 느리게 될 것이고,
ack를 0 또는 1로 할 경우에는 속도가 매우 빠르게 되지만 데이터 유실이 발생할 수 있죠.
그렇기 때문에 카프카를 통해 사용하고자 하는 데이터의 특성에 따라 자체적으로 정책을 정하고 옵션을 선택하여 사용하시면 됩니다.
금융 데이터와 같이 유실되면 안되는 데이터라면 느리더라도(ack 0, 1에 비해 느린 것입니다) ack all로 사용하시고,
유실되도 무관한 센서 데이터의 경우 ack를 0 또는 1로 설정하시는 것을 추천드립니다.
현업에서도 이러한 정책에 따라 ack옵션을 선택하여 사용하게 된답니다.
```

```
3개의 브로커 사용시 3개 레플리케이션을 추천하는 이유
운영상의 이슈(데이터의 유실, 복구 불가 등)를 최대한 배제하기 위해서입니다.
카프카 브로커 버젼 업그레이드같은 상황을 예를 들 수 있을 것 같습니다.
카프카 브로커 버젼을 업그레이드 하려면 브로커 3대를 한대씩 종료/실행(여러번)해야합니다.
만약 1대의 브로커를 종료했을때 운이 좋지 않아서 동시에 나머지 replica를 가진 broker가 down된다면 해당 토픽은 복구되지 못합니다.
 Kafka broker가 설치된 서버의 가용성이 99.9%라고 가정하더라도 365일중 shutdown되는 시간은 무려 8시간이므로
카프카 브로커 버젼을 업그레이드 하는 작업을 하던 도중 서버가 동시에 죽을 가능성이 없다고 보기는 힘듭니다.
빅데이터 운영에 있어서 중요한 것은 장애가 발생하는지/안하는지가 아니라 장애가 발생했을 시에 복구가 가능한지/불가능 한지가 더 중요하다고 생각됩니다.
이를 고려하셔서 replication factor를 정하시면 될것입니다.
데이터 유실이 되면 치명적이라고 생각된다면 3이상으로 설정하셔서 운영하시고,
만약 일부 유실이 되도 무관한 데이터라면 리소스 효율화를 위해 replication factor을 2나 1로 낮추어 운영하셔도 좋은 방법이라 봅니다!
```
